# 操作系统



资料参考：

1. 牛客网面试宝典操作系统部分

2. <https://github.com/CyC2018/CS-Notes/blob/master/notes/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E7%9B%AE%E5%BD%95.md>

3. <https://github.com/wolverinn/Waking-Up/blob/master/Operating%20Systems.md>
4. [面试/笔试第二弹 —— 操作系统面试问题集锦](https://blog.csdn.net/justloveyou_/article/details/78304294?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task)

---

## 操作系统概述

### 基本特征

---

#### **1. 并发与并行**

操作系统通过引入进程和线程，使得程序能够并发运行。

并发（concurrency）：指宏观上看起来两个程序在同时运行，比如说在单核cpu上的多任务。但是从微观上看两个程序的指令是交织着运行的，你的指令之间穿插着我的指令，我的指令之间穿插着你的，在单个周期内只运行了一个指令。这种并发并不能提高计算机的性能，只能提高效率。

并行（parallelism）：指严格物理意义上的同时运行，比如多核cpu，两个程序分别运行在两个核上，两者之间互不影响，单个周期内每个程序都运行了自己的指令，也就是运行了两条指令。这样说来并行的确提高了计算机的效率。所以现在的cpu都是往多核方面发展。并行需要硬件支持，如多流水线、多核处理器或者分布式计算系统。

#### **2. 共享**

共享是指系统中的资源可以被多个并发进程共同使用。

有两种共享方式：互斥共享和同时共享。

互斥共享的资源称为临界资源，例如打印机等，在同一时刻只允许一个进程访问，需要用同步机制来实现互斥访问。操作临界资源的代码段成为临界区。

临界资源--》同步机制--》 信号量（PV操作），事件 ，（锁）互斥量

#### **3. 虚拟**

虚拟技术把一个物理实体转换为多个逻辑实体。

主要有两种虚拟技术：时（时间）分复用技术和空（空间）分复用技术。

多个进程能在同一个处理器上并发执行使用了时分复用技术，让每个进程轮流占用处理器，每次只执行一小个时间片并快速切换。进程、线程的调度，时分复用。

虚拟内存使用了空分复用技术，它将物理内存抽象为地址空间，每个进程都有各自的地址空间。地址空间的页被映射到物理内存，地址空间的页并不需要全部在物理内存中，当使用到一个没有在物理内存的页时，执行页面置换算法，将该页置换到内存中。（虚拟地址详细见后面）

### 操作系统的基本功能

---

#### **1.进程管理**

进程控制、进程同步、进程通信、死锁处理、处理机调度等。

进程控制：进程的概念,僵尸进程
进程同步：临界资源的保护
进程通信：管道，系统IPC，锁 等。
死锁处理：死锁产生的原理，如何避免，处理
处理机调度：调度算法，经典的算法：先来先服务等。

---

#### **2.内存管理**

内存分配、地址映射、内存保护与共享、虚拟内存等。

内存分配：可执行文件的内存分配，BSS，data，text段的分配。
地址映射：虚拟地址的映射，二级->三级 地址映射
内存保护：
虚拟内存：

---

#### **3.文件管理**

文件存储空间的管理、目录管理、文件读写管理和保护等。

课设内容：实现的简单的文件系统。UNIXV6++的文件存储空间分布，diskinode和inode，文件表的关系，Unix的inode管理

---

#### **4.设备管理**

完成用户的 I/O 请求，方便用户使用各种设备，并提高设备的利用率。

主要包括缓冲管理、设备分配、设备处理、虛拟设备等。

缓冲管理：缓冲队列，自由队列

### **系统调用**

---

进程在用户态使用内核功能时，转换为内核态，操作系统负责完成。Linux的基本系统调用有

|任务|命令函数|
|-|-|
|进程的控制|fork() ;exit();wait();
|进程通信| pipe(); shmget();mmap();
|文件操作| open();read();write();
|设备操作| read();wriet();
|进程相关| getpid();getppid();sleep();usleep();
|系统安全| chmod(); umask();chown()

### **中断**

---

#### **1.外设备中断**

---
io完成，输入输出设备的中断

#### **2.异常**

---
由 CPU 执行指令的内部事件引起，如非法操作码、地址越界、算术溢出等。

#### **3.系统调用**

---
程序中使用系统调用，会引发中断

#### **4.时钟中断**

---
时钟中断会引发一系列操作，时钟计数，进程的调度，进程优先级的重新计算等等。

## 进程部分

这一部分为操作系统知识的详细解释，可能成为直接面试题目

---

### **进程和线程的联系与区别**

---
**1. 基本概念**
进程是对运行时程序的封装，是系统进行资源调度和分配的的基本单位，实现了操作系统的并发；


线程是进程的子任务，是CPU调度和分派的基本单位，用于保证程序的实时性，实现进程内部的并发；线程是操作系统可识别的最小执行和调度单位。每个线程都独自占用一个虚拟处理器：独自的寄存器组，指令计数器和处理器状态。每个线程完成不同的任务，但是共享同一地址空间（也就是同样的动态内存，映射文件，目标代码等等），打开的文件队列和其他内核资源。也就是说：
|线程共享的数据|线程独占的数据|
|:--|-|
|进程代码段<br>进程的公有数据（全局变量、静态变量..<br>进程打开的文件描述符<br>进程的当前目录<br>信号处理器/信号处理函数：对收到的信号的处理方式<br>进程ID与进程组ID|线程ID<br>一组寄存器的值<br>线程自身的栈（堆是共享的）<br>错误返回码：线程可能会产生不同的错误返回码，一个线程的错误返回码不应该被其它线程修改；<br>信号掩码/信号屏蔽字(Signal mask)：表示是否屏蔽/阻塞相应的信号(SIGKILL,SIGSTOP除外)|

**2.区别**
1.一个线程只能属于一个进程，而一个进程可以有多个线程，但至少有一个线程。线程依赖于进程而存在。

2.进程在执行过程中拥有独立的内存单元，而多个线程共享进程的内存。（资源分配给进程，同一进程的所有线程共享该进程的所有资源。同一进程中的多个线程共享代码段（代码和常量），数据段（全局变量和静态变量），扩展段（堆存储）。但是每个线程拥有自己的栈段，栈段又叫运行时段，用来存放所有局部变量和临时变量。）

3.进程是资源分配和调度的最小单位，线程是CPU调度和分派的最小单位；

4.系统开销： 由于在创建或撤消进程时，系统都要为之分配或回收资源，如内存空间、I／o设备等。因此，操作系统所付出的开销将显著地大于在创建或撤消线程时的开销。类似地，在进行进程切换时，涉及到整个当前进程CPU环境的保存以及新被调度运行的进程的CPU环境的设置。而线程切换只须保存和设置少量寄存器的内容，并不涉及存储器管理方面的操作。可见，进程切换的开销也远大于线程切换的开销。

5.通信：由于同一进程中的多个线程具有相同的地址空间，致使它们之间的同步和通信的实现，也变得比较容易。线程间可以直接读写进程数据段（如全局变量）来进行通信——需要进程同步和互斥手段的辅助，以保证数据的一致性。在有的系统中，线程的切换、同步和通信都无须操作系统内核的干预。进程的通信需要以进程间通信（IPC）的方式进行。（下一点会有详细解释）。

6.进程编程调试简单可靠性高，但是创建销毁开销大；线程正相反，开销小，切换速度快，但是编程调试相对复杂。

7.进程间不会相互影响 ；线程一个线程挂掉将导致整个进程挂掉。

8.进程适应于多核、多机分布；线程适用于多核

9.多进程和多线程的不同：进程是资源分配的最小单位，而线程时CPU调度的最小单位。多线程之间共享同一个进程的地址空间，线程间通信简单，同步复杂，线程创建、销毁和切换简单，速度快，占用内存少，适用于多核分布式系统，但是线程间会相互影响，一个线程意外终止会导致同一个进程的其他线程也终止，程序可靠性弱。而多进程间拥有各自独立的运行地址空间，进程间不会相互影响，程序可靠性强，但是进程创建、销毁和切换复杂，速度慢，占用内存多，进程间通信复杂，但是同步简单，适用于多核、多机分布。

---
**3.进程之间的通信**
进程间通信主要包括管道、系统IPC（包括消息队列、信号量、信号、共享内存等）、以及套接字socket。

1.管道：

管道主要包括无名管道和命名管道:管道可用于具有亲缘关系的父子进程间的通信，有名管道除了具有管道所具有的功能外，它还允许无亲缘关系进程间的通信

1.1 普通管道PIPE：

1)它是半双工的（即数据只能在一个方向上流动），具有固定的读端和写端

2)它只能用于具有亲缘关系的进程之间的通信（也是父子进程或者兄弟进程之间）

3)它可以看成是一种特殊的文件，对于它的读写也可以使用普通的read、write等函数。但是它不是普通的文件，并不属于其他任何文件系统，并且只存在于内存中。

1.2 命名管道FIFO：

1)FIFO可以在无关的进程之间交换数据

2)FIFO有路径名与之相关联，它以一种特殊设备文件形式存在于文件系统中。


1. 系统IPC：

2.1 消息队列

消息队列，是消息的链接表，存放在内核中。一个消息队列由一个标识符（即队列ID）来标记。 (消息队列克服了信号传递信息少，管道只能承载无格式字节流以及缓冲区大小受限等特点)具有写权限得进程可以按照一定得规则向消息队列中添加新信息；对消息队列有读权限得进程则可以从消息队列中读取信息；

特点：

1)消息队列是面向记录的，其中的消息具有特定的格式以及特定的优先级。

2)消息队列独立于发送与接收进程。进程终止时，消息队列及其内容并不会被删除。

3)消息队列可以实现消息的随机查询,消息不一定要以先进先出的次序读取,也可以按消息的类型读取。

4)读进程可以根据消息类型有选择地接收消息，而不像 FIFO 那样只能默认地接收。

2.2 信号量semaphore

信号量（semaphore）与已经介绍过的 IPC 结构不同，它是一个计数器，可以用来控制多个进程对共享资源的访问。信号量用于实现进程间的互斥与同步，而不是用于存储进程间通信数据。

特点：

1)信号量用于进程间同步，若要在进程间传递数据需要结合共享内存。

2)信号量基于操作系统的 PV 操作，程序对信号量的操作都是原子操作。

3)每次对信号量的 PV 操作不仅限于对信号量值加 1 或减 1，而且可以加减任意正整数。

4)支持信号量组。


2.3 信号signal

信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。

可以使用系统信号，也可以自定义使用信号，#35-#63 信号，其他由系统定义。

2.4 共享内存（Shared Memory）

它使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据得更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等

特点：

1)共享内存是最快的一种IPC，因为进程是直接对内存进行存取

2)因为多个进程可以同时操作，所以需要进行同步

3)信号量+共享内存通常结合在一起使用，信号量用来同步对共享内存的访问


3.套接字SOCKET：

socket也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同主机之间的进程通信。

网络socket 可以不同主机之间的进程通信，也可以本机通信。
unix socket 可以用于本机进程之间的通信，原理与网络socket类似。

### 进程之间的通信

参考

[进程间通信IPC (InterProcess Communication)--简书](https://www.jianshu.com/p/c1015f5ffa74)

[进程间通信--管道](http://blog.chinaunix.net/uid-26833883-id-3227144.html)

[进程间通信---共享内存](http://blog.chinaunix.net/uid-26833883-id-3230564.html)

[进程间通信——共享内存（Shared Memory）--CSDN](https://blog.csdn.net/ypt523/article/details/79958188?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task)

[进程间同步---system v ipc 对象信号灯集--PV信号量操作](http://blog.chinaunix.net/uid-26833883-id-3230813.html)



### **进程同步**

---

**1. 临界区**
对临界资源进行访问的那段代码称为临界区。
为了互斥访问临界资源，每个进程在进入临界区之前，需要先进行检查。
**2. 同步与互斥**

* 同步：多个进程因为合作产生的直接制约关系，使得进程有一定的先后执行关系。
* 互斥：多个进程在同一时刻只有一个进程能进入临界区。

#### 经典同步问题

1.生产者-消费者问题

```C++
问题描述：使用一个缓冲区来存放数据，只有缓冲区没有满，生产者才可以写入数据；只有缓冲区不为空，消费者才可以读出数据

// 伪代码描述 
// 定义信号量 full记录缓冲区物品数量 empty代表缓冲区空位数量 mutex为互斥量
semaphore full = 0, empty = n, mutex = 1;

// 生产者进程
void producer(){
    do{
      P(empty);
      P(mutex);

     // 生产者进行生产

      V(mutex);
      V(full);
    } while(1);
}

void consumer(){
    do{
     P(full);
      P(mutex);

    // 消费者进行消费

      V(mutex);
      V(empty);
    } while(1);
}
```

2.哲学家就餐问题

```C++

```

3.读写者问题

```C++

```


### **进程状态以及调度**

***进程有三种基本的状态：***

* 就绪状态：进程已获得除处理机以外的所需资源，等待分配处理机资源
* 运行状态：占用处理机资源运行，处于此状态的进程数小于等于CPU数
* 阻塞状态： 进程等待某种条件，在条件满足之前无法执行

#### 进程调度算法

---

##### 批处理系统

批处理系统没有太多的用户操作，在该系统中，调度算法目标是保证吞吐量和周转时间（从提交到终止的时间）。

**1 先来先服务 first-come first-serverd（FCFS）**
非抢占式的调度算法，按照请求的顺序进行调度。

有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。

**2 短作业优先 shortest job first（SJF）**
非抢占式的调度算法，按估计运行时间最短的顺序进行调度。

长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。

**3 最短剩余时间优先 shortest remaining time next（SRTN）**
最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。 当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。

**4 最高响应比优先 Highest Response Ratio Next（HRRN）**
响应比 = 1+ 等待时间/处理时间。同时考虑了等待时间的长短和估计需要的执行时间长短，很好的平衡了长短进程。非抢占，吞吐量高，开销可能较大，提供好的响应时间，无饥饿问题。

##### 交互式系统

交互式系统有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应。

**1 时间片轮转**
将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。

时间片轮转算法的效率和时间片的大小有很大关系：

因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。
而如果时间片过长，那么实时性就不能得到保证。

**2.2 优先级调度**
为每个进程分配一个优先级，按优先级进行调度。

为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。

**3 多级反馈队列**
一个进程需要执行 100 个时间片，如果采用时间片轮转调度算法，那么需要交换 100 次。

多级队列是为这种需要连续执行多个时间片的进程考虑，它设置了多个队列，每个队列时间片大小都不同，例如 1,2,4,8,..。进程在第一个队列没执行完，就会被移到下一个队列。这种方式下，之前的进程只需要交换 7 次。

每个队列优先权也不同，最上面的优先权最高。因此只有上一个队列没有进程在排队，才能调度当前队列上的进程。

可以将这种调度算法看成是时间片轮转调度算法和优先级调度算法的结合。

---

### 僵尸进程

***僵尸进程的概念***
一个子进程结束后，它的父进程并没有等待它（调用wait或者waitpid），那么这个子进程将成为一个僵尸进程。僵尸进程是一个已经死亡的进程，但是并没有真正被销毁。它已经放弃了几乎所有内存空间，没有任何可执行代码，也不能被调度，仅仅在进程表中保留一个位置，记载该进程的进程ID、终止状态以及资源利用信息(CPU时间，内存使用量等等)供父进程收集，除此之外，僵尸进程不再占有任何内存空间。这个僵尸进程可能会一直留在系统中直到系统重启。

危害：占用进程号，而系统所能使用的进程号是有限的，在高并发的系统中，若存在大量的僵死进程，占用进程号，则导致系统无法创建更多进程，系统效率降低；占用内存，造成内存紧张，系统消耗会增大。

linux中ps命令查看进程状态。

***以下情况不会产生僵尸进程***

* 该进程的父进程先结束了。每个进程结束的时候，系统都会扫描是否存在子进程，如果有则用Init进程接管，成为该进程的父进程，并且会调用wait等待其结束。
* 父进程调用wait或者waitpid等待子进程结束（需要每隔一段时间查询子进程是否结束）。wait系统调用会使父进程暂停执行，直到它的一个子进程结束为止。waitpid则可以加入WNOHANG(wait-no-hang)选项，如果没有发现结束的子进程，就会立即返回，不会将调用waitpid的进程阻塞。同时，waitpid还可以选择是等待任一子进程（同wait），还是等待指定pid的子进程，还是等待同一进程组下的任一子进程，还是等待组ID等于pid的任一子进程；
* 子进程结束时，系统会产生SIGCHLD(signal-child)信号，可以注册一个信号处理函数，在该函数中调用waitpid，等待所有结束的子进程（注意：一般都需要循环调用waitpid，因为在信号处理函数开始执行之前，可能已经有多个子进程结束了，而信号处理函数只执行一次，所以要循环调用将所有结束的子进程回收）；
* 也可以用signal(SIGCLD, SIG_IGN)(signal-ignore)通知内核，表示忽略SIGCHLD信号，那么子进程结束后，内核会进行回收。


***孤儿进程***

* 一个父进程已经结束了，但是它的子进程还在运行，那么这些子进程将成为孤儿进程。孤儿进程会被Init（进程ID为1）接管，当这些孤儿进程结束时由Init完成状态收集工作。

---

### 线程同步的方式

#### 信号量

* 信号量是一种特殊的变量，可用于线程同步。它只取自然数值，并且只支持两种操作：

```txt
P(SV):如果信号量SV大于0，将它减一；如果SV值为0，则挂起该线程。

V(SV)：如果有其他进程因为等待SV而挂起，则唤醒，然后将SV+1；否则直接将SV+1。

其系统调用为：

sem_wait（sem_t *sem）：以原子操作的方式将信号量减1，如果信号量值为0，则sem_wait将被阻塞，直到这个信号量具有非0值。

sem_post（sem_t *sem)：以原子操作将信号量值+1。当信号量大于0时，其他正在调用sem_wait等待信号量的线程将被唤醒。
```

#### 互斥量

互斥量又称互斥锁，主要用于线程互斥，不能保证按序访问，可以和条件锁一起实现同步。当进入临界区      时，需要获得互斥锁并且加锁；当离开临界区时，需要对互斥锁解锁，以唤醒其他等待该互斥锁的线程。其主要的系统调用如下：

```txt
pthread_mutex_init:初始化互斥锁

pthread_mutex_destroy：销毁互斥锁

pthread_mutex_lock：以原子操作的方式给一个互斥锁加锁，如果目标互斥锁已经被上锁，pthread_mutex_lock调用将阻塞，直到该互斥锁的占有者将其解锁。

pthread_mutex_unlock:以一个原子操作的方式给一个互斥锁解锁
```

#### 条件变量

条件变量，又称条件锁，用于在线程之间同步共享数据的值。条件变量提供一种线程间通信机制：当某个共享数据达到某个值时，唤醒等待这个共享数据的一个/多个线程。即，当某个共享变量等于某个值时，调用 signal/broadcast。此时操作共享变量时需要加锁。其主要的系统调用如下：

```txt
pthread_cond_init:初始化条件变量

pthread_cond_destroy：销毁条件变量

pthread_cond_signal：唤醒一个等待目标条件变量的线程。哪个线程被唤醒取决于调度策略和优先级。

pthread_cond_wait：等待目标条件变量。需要一个加锁的互斥锁确保操作的原子性。该函数中在进入wait状态前首先进行解锁，然后接收到信号后会再加锁，保证该线程对共享资源正确访问。
```

### 多进程和多线程的使用场景

* 多线程模型主要优势为线程间切换代价较小，因此适用于I/O密集型的工作场景，因此I/O密集型的工作场景经常会由于I/O阻塞导致频繁的切换线程。同时，多线程模型也适用于单机多核分布式场景。

* 多进程模型，适用于CPU密集型。同时，多进程模型也适用于多机分布式场景中，易于多机扩展。

### 互斥量与临界区的区别

互斥量是可以命名的，可以用于不同进程之间的同步；而临界区只能用于同一进程中线程的同步。创建互斥量需要的资源更多，因此临界区的优势是速度快，节省资源。

### 什么是IO多路复用？实现方法？

#### io复用概念以及原理

IO多路复用（IO Multiplexing）是指单个进程/线程就可以同时处理多个IO请求。

实现原理：用户将想要监视的文件描述符（File Descriptor）添加到select/poll/epoll函数中，由内核监视，函数阻塞。一旦有文件描述符就绪（读就绪或写就绪），或者超时（设置timeout），函数就会返回，然后该进程可以进行相应的读/写操作。

* 三个函数的使用见计网作业。

#### select/poll/epoll三个方式的使用

##### select：

* 将文件描述符放入一个集合中，调用select时，将这个集合从用户空间拷贝到内核空间，由内核根据就绪状态修改该集合的内容。集合大小有限制，32位机默认是1024（64位：2048）；采用水平触发机制。select函数返回后，需要通过遍历这个集合，找到就绪的文件描述符，当文件描述符的数量增加时，效率会线性下降；
* **select的缺点：** 每次都要复制，开销大; 集合的大小有限，默认1024/2048的大小，连接数量有限；轮询的方式效率较低，每次都要轮询集合中的文件描述符

##### poll：

* 和select几乎没有区别，区别在于文件描述符的存储方式不同，poll采用链表的方式存储，没有最大存储数量的限制。
* 缺点：和select类似，但是：不用复制，只需要将文件描述符加入数组即可。仍然采用轮询的方式查询数组中的文件描述符，效率较低。
* 采用水平触发的方式。

##### epoll： 

* 通过内核和用户空间共享内存，避免了不断复制的问题；支持的同时连接数上限很高（1G左右的内存支持10W左右的连接数）；文件描述符就绪时，采用回调机制，避免了轮询（回调函数将就绪的描述符添加到一个链表中，执行epoll_wait时，返回这个链表）；支持水平触发和边缘触发，采用边缘触发机制时，只有活跃的描述符才会触发回调函数。
* epoll的ET模式是默认模式，这也是select和poll的模式，即只要有事件发生，那么就会被epoll_wait所捕获，如果一次读写没有完成，那么会在下一次epoll_wait调用时接着被捕获；而ET边沿触发模式是读写没完成，下次不会被捕获，之后新的数据到达时才会触发。

###### 水平触发和边缘触发

* 水平触发（LT，Level Trigger）模式下，只要一个文件描述符就绪，就会触发通知，如果用户程序没有一次性把数据读写完，下次还会通知；
* 边缘触发（ET，Edge Trigger）模式下，当描述符从未就绪变为就绪时通知一次，之后不会再通知，直到再次从未就绪变为就绪（缓冲区从不可读/写变为可读/写）。用户需要判断数据是否读完，否则需要等待下一次文件描述符变就绪状态才能接收到通知。
* 区别：边缘触发效率更高，减少了被重复触发的次数，函数不会返回大量用户程序可能不需要的文件描述符。
* 为什么边缘触发一定要用非阻塞（non-block）IO：避免由于一个描述符的阻塞读/阻塞写操作让处理其它描述符的任务出现饥饿状态。

***select/poll/epoll小结：***

* 线程能连接的最大数量
* 文件描述符的传递方式
* 水平触发 or 边缘触发
* 查询文件描述符的方式 ： 轮询or回调
* 表面上看epoll的性能最好，但是在连接数量较少的并且十分都活跃的情况下，select和poll的性能可能要高与epoll，因为epoll设计到函数的回调。三种方式的效率需要根据实际情况来考虑。

#### 常见的io模型

* 同步阻塞IO（Blocking IO）：用户线程发起IO读/写操作之后，线程阻塞，直到可以开始处理数据；对CPU资源的利用率不够；
* 同步非阻塞IO（Non-blocking IO）：发起IO请求之后可以立即返回，如果没有就绪的数据，需要不断地发起IO请求直到数据就绪；不断重复请求消耗了大量的CPU资源；
* IO多路复用
* 异步IO（Asynchronous IO）：用户线程发出IO请求之后，继续执行，由内核进行数据的读取并放在用户指定的缓冲区内，在IO完成之后通知用户线程直接使用。

---

## 死锁部分

### 死锁的概念以及死锁产生的必要条件

***死锁的概念***

* 在两个或者多个并发进程中，每个进程持有某种资源而又等待其它进程释放它们现在保持着的资源，在未改变这种状态之前都不能向前推进，称这一组进程产生了死锁(deadlock)。

***产生死锁的四个条件***

* **互斥条件：** 进程对所分配到的资源不允许其他进程访问，若其他进程访问该资源，只能等待，直至占有该资源的进程使用完成后释放该资源

* **请求和保持条件：** 进程获得一定的资源后，又对其他资源发出请求，但是该资源可能被其他进程占有，此时请求阻塞，但该进程不会释放自己已经占有的资源。

* **不可剥夺条件：** 进程已获得的资源，在未完成使用之前，不可被剥夺，只能在使用后自己释放

* **环路等待条件：** 进程发生死锁后，必然存在一个进程-资源之间的环形链 

### 死锁的处理方法

* 鸵鸟策略
* 死锁检测与死锁恢复
* 死锁预防
* 死锁避免

#### 落鸟策略

是指忽略死锁。当死锁不会对用户造成太大影响或者发生死锁的概率很低时，可以采取鸵鸟策略

#### 死锁检测与恢复

不试图阻止死锁，当检测到死锁时，采取措施进行恢复

##### 死锁解锁

可以利用有向图检测是否存在环

##### 死锁恢复的方法

* 利用抢占恢复： 挂起某些进程，然后抢占这些进程的资源，但是需要恢复这些被挂起进程的状态
* 利用回滚恢复： 让后写进程回退到足以解除死锁的状态，进程回退时资源释放资源
* 通过杀死进程恢复： 强制杀死某些进程以解锁死锁


#### 死锁预防

***死锁预防的基本思想是破坏形成死锁的基本条件***

#### 死锁避免

在程序运行时避免死锁的发生

银行家算法： 只要存在一种资源分配方式，使得系统是安全的即可。

---

## 下一部分为内存管理

### 虚拟内存

每个程序都拥有自己的地址空间，这个地址空间被分成大小相等的页，这些页被映射到物理内存；但不需要所有的页都在物理内存中，当程序引用到不在物理内存中的页时，由操作系统将缺失的部分装入物理内存。这样，对于程序来说，逻辑上似乎有很大的内存空间，只是实际上有一部分是存储在磁盘上，因此叫做虚拟内存。

虚拟内存的优点是让程序可以获得更多的可用内存。

#### linux的虚地址空间

* linux虚地址空间即是虚拟内存

虚拟内存技术使得不同进程在运行过程中，它所看到的是自己独自占有了当前系统的4G内存。所有进程共享同一物理内存，每个进程只把自己目前需要的虚拟内存空间映射并存储到物理内存上。 事实上，在每个进程创建加载时，内核只是为进程“创建”了虚拟内存的布局，具体就是初始化进程控制表中内存相关的链表，实际上并不立即就把虚拟内存对应位置的程序数据和代码（比如.text .data段）拷贝到物理内存中，只是建立好虚拟内存和磁盘文件之间的映射就好（叫做存储器映射），等到运行到对应的程序时，才会通过缺页异常，来拷贝数据。还有进程运行过程中，要动态分配内存，比如malloc时，也只是分配了虚拟内存，即为这块虚拟内存对应的页表项做相应设置，当进程真正访问到此数据时，才引发缺页异常。

请求分页系统、请求分段系统和请求段页式系统都是针对虚拟内存的，通过请求实现内存与外存的信息置换。

#### 虚拟内存的好处

* 1.扩大地址空间；
* 2.内存保护：每个进程运行在各自的虚拟内存地址空间，互相不能干扰对方。虚存还对特定的内存地址提供写保护，可以防止代码或数据被恶意篡改。
* 3.公平内存分配。采用了虚存之后，每个进程都相当于有同样大小的虚存空间。
* 4.当进程通信时，可采用虚存共享的方式实现。
* 5.当不同的进程使用同样的代码时，比如库文件中的代码，物理内存中可以只存储一份这样的代码，不同的进程只需要把自己的虚拟内存映射过去就可以了，节省内存
* 6.虚拟内存很适合在多道程序设计系统中使用，许多程序的片段同时保存在内存中。当一个程序等待它的一部分读入内存时，可以把CPU交给另一个进程使用。在内存中可以保留多个进程，系统并发度提高
* 7.在程序需要分配连续的内存空间的时候，只需要在虚拟内存空间分配连续空间，而不需要实际物理内存的连续空间，可以利用碎片

#### 虚拟内存的代价

* 1.虚存的管理需要建立很多数据结构，这些数据结构要占用额外的内存
* 2.虚拟地址到物理地址的转换，增加了指令的执行时间。
* 3.页面的换入换出需要磁盘I/O，这是很耗时的
* 4.如果一页中只有一部分数据，会浪费内存。

### 内核中内存的管理

  一个程序的本质是由BSS段，data段（数据），text段（代码段）组成的。一个可执行程序没有调入内存之前，分为代码段，数据，未初始化数据区三个部分。调入内存之后，内存中由低地址到高地址依次为： 代码段，数据段{已初始化数据段，未初始化数据段(BBS)}，堆（heap，向高地址增长），栈（stack，向低地址增长），命令行参数和环境变量。

  **BSS段** :（bss segment）通常是指用来存放程序中未初始化的全局变量的一块内存区域。BSS是英文Block Started by Symbol的简称。BSS段属于静态内存分配。
  **数据段** ：数据段（data segment）通常是指用来存放程序中 已初始化 的 全局变量 的一块内存区域。数据段属于静态内存分配。
  **代码段**： 代码段（code segment/text segment）通常是指用来存放 程序执行代码 的一块内存区域。这部分区域的大小在程序运行前就已经确定，并且内存区域通常属于 只读 , 某些架构也允许代码段为可写，即允许修改程序。在代码段中，也有可能包含一些 只读的常数变量 ，例如字符串常量等。程序段为程序代码在内存中的映射.一个程序可以在内存中多有个副本.
  **堆（heap）** ：堆是用于存放进程运行中被动态分配的内存段，它的大小并不固定，可动态扩张或缩减。当进程调用malloc/free等函数分配内存时，新分配的内存就被动态添加到堆上（堆被扩张）/释放的内存从堆中被剔除（堆被缩减）
  **栈(stack)** ：栈又称堆栈， 存放程序的 局部变量 （但不包括static声明的变量， static 意味着 在数据段中 存放变量）。除此以外，在函数被调用时，栈用来传递参数和返回值。由于栈的先进先出特点，所以栈特别方便用来保存/恢复调用现场。储动态内存分配,需要程序员手工分配,手工释放

* 参考博客：
    <https://www.cnblogs.com/zafu/p/7399859.html>
    <https://blog.csdn.net/yangcunbiao/article/details/83020443>

### 分系统中虚地址与物理内存的映射

* **内存管理单元（MMU）**管理着逻辑地址和物理地址的转换，其中的页表（Page table）存储着页（逻辑地址）和页框（物理内存空间）的映射表，页表中还包含包含有效位（是在内存还是磁盘）、访问位（是否被访问过）、修改位（内存中是否被修改过）、保护位（只读还是可读写）。逻辑地址：页号+页内地址（偏移）；每个进程一个页表，放在内存，页表起始地址在PCB/寄存器中。

* 虚地址与物理地址的映射，unix最原始的为二级页表，随着系统的增长，三级页表，四级页表系统会出现。二级页表详情见操作系统上课讲义（期末考过，记住）。

### 页面置换算法

#### 最佳页面置换算法OPT（Optimal replacement algorithm）

* 置换以后不需要或者最远的将来才需要的页面，是一种理论上的算法，是最优策略；实现上来说不知道不知道哪一个页面是将来不需要或者很久之后才需要的页面，因此实际无法操作

#### 先进先出FIFO

* 置换在内存中驻留时间最长的页面。缺点：有可能将那些经常被访问的页面也被换出，从而使缺页率升高；先进先出策略，将cache作为栈看作，需要记录页面进入时间。

#### 第二次机会算法SCR

* 按FIFO选择某一页面，若其访问位为1，给第二次机会，并将访问位置0；

#### 时钟算法 Clock

* SCR中需要将页面在链表中移动（第二次机会的时候要将这个页面从链表头移到链表尾），时钟算法使用环形链表，再使用一个指针指向最老的页面，避免了移动页面的开销；

#### 近未使用算法NRU（Not Recently Used）

* 检查访问位R、修改位M，优先置换R=M=0，其次是（R=0, M=1）；

#### 最近最少使用算法LRU（Least Recently Used）

* 置换出未使用时间最长的一页；实现方式：维护时间戳，或者维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。

#### 最不经常使用算法NFU

* 置换出访问次数最少的页面

#### 在学校操作系统课程中，自己的关于页面的一个想法

* 将cache分为两个部分，一个部分为hot部分，占cache的3/8，hot部分存放的是近期使用过k次（及以上）的页面；剩下部分为cool部分，占cache的5/8。发生页面置换时，若页面已经在hot部分，则增加改页面最近的访问次数，hot值降低；若页面在cool部分，则该页面hot+1，若该页面最近访问次数达到k，则置换到cache的hot部分，hot部分被置换出来的页面保留在cool部分；若页面不在cache中，则将页面置换到cool部分，将cool部分的某一个近期没有使用过的页面置换出来

### 分页、分段

该部分详细见操作系统讲义

#### 分段

段式存储：用户进程地址空间按照自身逻辑关系划分为若干个段（segment）（如代码段，数据段，堆栈段），内存空间被动态划分为长度不同的区域，分配时以段为单位，每段在内存中占据连续空间，各段可以不相邻；

#### 分页

页式存储：用户空间划分为大小相等的部分称为页（page），内存空间划分为同样大小的区域称为页框，分配时以页为单位，按进程需要的页数分配，逻辑上相邻的页物理上不一定相邻；

#### 段页

段页式存储：用户进程先按段划分，段内再按页划分，内存划分和分配按页。

#### 三者区别联系

##### 目的不同

分页的目的是管理内存，用于虚拟内存以获得更大的地址空间；分段的目的是满足用户的需要，使程序和数据可以被划分为逻辑上独立的地址空间；

##### 大小不同

段的大小不固定，由其所完成的功能决定；页的大小固定，由系统决定；

##### 地址空间维度不同

分段是二维地址空间（段号+段内偏移），分页是一维地址空间（每个进程一个页表/多级页表，通过一个逻辑地址就能找到对应的物理地址）；

##### 碎片和信息保护

* 分段没有内碎片，但是会产生外碎片；分页没有外碎片，但是会产生内碎片，一个页填不满的情况
* 分段便于信息的保护和共享；分页的共享收到了限制；

### 局部性原理

* 时间上：最近被访问的页在不久的将来还会被访问；
* 空间上：内存中被访问的页周围的页也很可能被访问。

### 颠簸现象

* 颠簸本质上是指频繁的页调度行为。进程发生缺页中断时必须置换某一页。然而，其他所有的页都在使用，它置换一个页，但又立刻再次需要这个页。因此会不断产生缺页中断，导致整个系统的效率急剧下降，这种现象称为颠簸。
* 内存颠簸的解决策略包括：

  * 修改页面置换算法；
  * 降低同时运行的程序的数量；
  * 终止该进程或增加物理内存容量。

---

## 设备管理

详情看操作系统讲义

---

## 程序的编译

### 源码到可执行程序的过程

#### 1）预编译

主要处理源代码文件中的以“#”开头的预编译指令。处理规则见下

* 1、删除所有的#define，展开所有的宏定义。

* 2、处理所有的条件预编译指令，如“#if”、“#endif”、“#ifdef”、“#elif”和“#else”。

* 3、处理“#include”预编译指令，将文件内容替换到它的位置，这个过程是递归进行的，文件中包含其他文件。

* 4、删除所有的注释，“//”和“/**/”。

* 5、保留所有的#pragma 编译器指令，编译器需要用到他们，如：#pragma once 是为了防止有文件被重复引用。

* 6、添加行号和文件标识，便于编译时编译器产生调试用的行号信息，和编译时产生编译错误或警告是能够显示行号。

#### 2）编译

详细见编译原理课程讲义

把预编译之后生成的xxx.i或xxx.ii文件，进行一系列词法分析、语法分析、语义分析及优化后，生成相应的汇编代码文件。

* 1、词法分析：利用类似于“有限状态机”的算法，将源代码程序输入到扫描机中，将其中的字符序列分割成一系列的记号。

* 2、语法分析：语法分析器对由扫描器产生的记号，进行语法分析，产生语法树。由语法分析器输出的语法树是一种以表达式为节点的树。

* 3、语义分析：语法分析器只是完成了对表达式语法层面的分析，语义分析器则对表达式是否有意义进行判断，其分析的语义是静态语义——在编译期能分期的语义，相对应的动态语义是在运行期才能确定的语义。

* 4、优化：源代码级别的一个优化过程。

* 5、目标代码生成：由代码生成器将中间代码转换成目标机器代码，生成一系列的代码序列——汇编语言表示。

* 6、目标代码优化：目标代码优化器对上述的目标机器代码进行优化：寻找合适的寻址方式、使用位移来替代乘法运算、删除多余的指令等。

### 3）汇编

将汇编代码转变成机器可以执行的指令(机器码文件)。 汇编器的汇编过程相对于编译器来说更简单，没有复杂的语法，也没有语义，更不需要做指令优化，只是根据汇编指令和机器指令的对照表一一翻译过来，汇编过程有汇编器as完成。经汇编之后，产生目标文件(与可执行文件格式几乎一样)xxx.o(Windows下)、xxx.obj(Linux下)。

#### 4）链接

将不同的源文件产生的目标文件进行链接，从而形成一个可以执行的程序。链接分为静态链接和动态链接

### 关于链接

链接分为动态链接和静态链接，详细见计网作业
参考博客

* <https://blog.csdn.net/kang___xi/article/details/80210717>

#### 静态链接

函数和数据被编译进一个二进制文件。在使用静态库的情况下，在编译链接可执行文件时，链接器从库中复制这些函数和数据并把它们和应用程序的其它模块组合起来创建最终的可执行文件。

空间浪费：因为每个可执行程序中对所有需要的目标文件都要有一份副本，所以如果多个程序对同一个目标文件都有依赖，会出现同一个目标文件都在内存存在多个副本；

更新困难：每当库函数的代码修改了，这个时候就需要重新进行编译链接形成可执行程序。

运行速度快：但是静态链接的优点就是，在可执行程序中已经具备了所有执行程序所需要的任何东西，在执行的时候运行速度快。

#### 动态链接

动态链接的基本思想是把程序按照模块拆分成各个相对独立部分，在程序运行时才将它们链接在一起形成一个完整的程序，而不是像静态链接一样把所有程序模块都链接成一个单独的可执行文件。

共享库：就是即使需要每个程序都依赖同一个库，但是该库不会像静态链接那样在内存中存在多分，副本，而是这多个程序在执行时共享同一份副本；

更新方便：更新时只需要替换原来的目标文件，而无需将所有的程序再重新链接一遍。当程序下一次运行时，新版本的目标文件会被自动加载到内存并且链接起来，程序就完成了升级的目标。

性能损耗：因为把链接推迟到了程序运行时，所以每次执行程序都需要进行链接，所以性能会有一定损失。

#### 区别

静态链接和动态链接的区别见上面详细介绍。
实际在计网作业中发现，静态链接而成的可执行程序往往要比动态链接的可执行程序要大，因为将所需要的库都包含在一个可执行文件中了。linux中默认为动态链接，可以根据编译选项，选择静态编译

## 文件系统

详见操作系统课程讲义

---
## Linux操作系统中常见的一些问题
---

#### ./ source sh 三个命令执行shell文件的区别

参考：
[linux 下的 source,sh,./三者区别--简书](https://www.jianshu.com/p/aa978c32935c)
[linux 下的 source,sh,./三者区别--CSDN-1](https://blog.csdn.net/s740556472/article/details/78176087)
